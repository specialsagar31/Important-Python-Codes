{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import,all_cols,warnings,dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#Getting python version\n",
    "from platform import python_version\n",
    "print(python_version())\n",
    "\n",
    "#To see all rows and columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "#To supress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#To check dtype of a column\n",
    "from pandas.api.types import infer_dtype\n",
    "#infer_dtype(df['col'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- intersect\n",
    "- multi-indexing problem\n",
    "- pivot \n",
    "- list_compre\n",
    "- merge\n",
    "- column of list\n",
    "- age from dob\n",
    "- replace values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To check common values between two columns\n",
    "np.intersect1d(df['col1'],df['col1']).size\n",
    "df=d1[d1['col1'].isin(d2['col1'])]\n",
    "\n",
    "\n",
    "# tackle multi-indexing problem\n",
    "grps.columns = ['_'.join(col) for col in grps.columns.values]\n",
    "\n",
    "\n",
    "#For grouping and counting in pivot.\n",
    "data=df.groupby(['loan_account_no','loan_payment_type']).agg({'loan_payment_type': 'count'})\\\n",
    ".rename(columns={'loan_payment_type':'count'}).reset_index()\\\n",
    ".pivot_table(index='loan_account_no',columns='loan_payment_type',values='count').fillna(0).reset_index()\n",
    "\n",
    "\n",
    "#Convert pivot values in %\n",
    "data.apply(lambda x: (x/x.sum())*100, axis=1).apply(lambda x: round(x,2))\n",
    "\n",
    "\n",
    "#List comprehension with 'and' and 'or'\n",
    "df['Channel_2'] = ['Regular' if i=='Green' else 'Delayed' if i=='Orange' else \\\n",
    "                    'Not_paid_recent' if (i=='Red' and j <- 0.1) else 'Erratic' for i,j in zip(df['Channel'],df['irr'])]\n",
    "\n",
    "\n",
    "#Merging two dfs and dropping common cols\n",
    "dfNew = df.merge(data, left_index=True, right_index=True,\n",
    "                 how='outer', suffixes=('', '_y'))\n",
    "dfNew.drop(dfNew.filter(regex='_y$').columns.tolist(),axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#Get values of a group in a list and then string\n",
    "mydf=data.groupby('loan_account_no')['col_list'].apply(list).reset_index()\n",
    "mydf['col_string']=[','.join(i) for i in mydf['col_list']]\n",
    "\n",
    "\n",
    "#Getting age from dob\n",
    "round(((pd.to_datetime(\"today\").normalize()-pd.to_datetime(csr['dob'])).dt.days)/365)\n",
    "\n",
    "\n",
    "#Replacing values\n",
    "df['loan_purpose'].replace(dict.fromkeys(['a','b','c'], 'z'),inplace=True)\n",
    "\n",
    "\n",
    "#Extracting only numbers from string\n",
    "df1['csr_id_y']=df1['csr_id_y'].str.extract('(\\d+)').astype('float')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary_scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binary scoring\n",
    "def binary_scoring(df, col_list, trans_col, loan_col):\n",
    "    \"\"\"\n",
    "    This functions takes transactional data and creates binary scoring monthly.\n",
    "    input:\n",
    "    ------\n",
    "        df : input pandas dataframe(dataframe)\n",
    "        col_list : list of columns for to group the data(month, loan account number)(list)\n",
    "        trans_col : amount column name(str)\n",
    "        loan_col : loan amount column name(str)\n",
    "    output:\n",
    "    -------\n",
    "        binary_df : binary dataframe with score and loan number\n",
    "    \"\"\"\n",
    "    \n",
    "    #################################################filtering_amount####################################################\n",
    "    temp_df = df.copy(deep=True) ## copying the data into another dataframe\n",
    "    temp_df = temp_df.groupby(col_list)[trans_col].agg(\"sum\").reset_index() ## grouping the data\n",
    "    temp_df = temp_df[temp_df[trans_col] >= 100] ## getting amount count more than 100\n",
    "    \n",
    "    \n",
    "    #################################################creating_binary_dataframe########################################## \n",
    "    ## getting binary dataframe using groupby\n",
    "    binary_df = temp_df.groupby(col_list)[loan_col].agg(\"count\").unstack().reset_index().transpose().reset_index()\n",
    "    binary_df = binary_df.fillna(0) ## filling na with 0\n",
    "    binary_df[\"total_trans\"] = [0] * binary_df.shape[0] ## creating new total trans column\n",
    "    for col in binary_df.columns[1:]:  ## imapping all column to integer\n",
    "        binary_df[col] = binary_df[col].astype(\"int\")\n",
    "        binary_df[\"total_trans\"] = binary_df[\"total_trans\"] + binary_df[col]\n",
    "        binary_df[\"total_trans\"] = [0] * binary_df.shape[0] ## creating new total count column\n",
    "    binary_df.columns = binary_df.iloc[0] ## making the top row as column\n",
    "    binary_df = binary_df.iloc[1:,:]  ## selecting rows from 2nd one\n",
    "    binary_df.rename(columns = {col_list[0] : loan_col}, inplace=True)  ## renaming column\n",
    "    binary_df.columns = binary_df.columns.astype(\"string\") ## columns to string\n",
    "    \n",
    "    \n",
    "    #################################################incremening_Score####################################################\n",
    "    inter_df = binary_df.iloc[:,1:].copy(deep=True) ## getting only one hot encoded data\n",
    "    col_name = inter_df.columns ## getting column names\n",
    "    \n",
    "    ## for each month running loop for score\n",
    "    for i in range(0,len(binary_df.columns[1:])-1):\n",
    "        \n",
    "        condition_one = inter_df[( inter_df[col_name[i]] ==0 ) & ( inter_df[col_name[i+1]] == 0 )] ## condition 1\n",
    "        binary_df.loc[ condition_one.index, col_name[i+1] ] = 0\n",
    "    \n",
    "        condition_two = inter_df[ ( inter_df[col_name[i]] ==0 ) & ( inter_df[col_name[i+1]] == 1 )]  ## condition 2\n",
    "        binary_df.loc[ condition_two.index, col_name[i+1] ] = 1\n",
    "        \n",
    "        condition_three = inter_df[ ( inter_df[col_name[i]] > 0 ) & ( inter_df[col_name[i+1]] == 0 )]  ## condition 3\n",
    "        binary_df.loc[ condition_three.index, col_name[i+1] ] = 0\n",
    "        \n",
    "        condition_four = inter_df[ ( inter_df[col_name[i]] > 0) & ( inter_df[col_name[i+1]] == 1 ) ]  ## condition 4\n",
    "        binary_df.loc[ condition_four.index, col_name[i+1] ] = binary_df.loc[ condition_four.index, col_name[i+1] ] + \\\n",
    "                                                               binary_df.loc[ condition_four.index, col_name[i] ]\n",
    "    \n",
    "    #################################################npv_score####################################################\n",
    "    binary_df['npv'] = [0] * binary_df.shape[0] ## getting all score zero with npv column\n",
    "    for idx, col in enumerate(col_name):  ## itreating data monthly and calculating score\n",
    "        monthly_npv = binary_df[ col ] / ( np.exp( -( idx + 1 ) ) ) \n",
    "        if idx != 0: binary_df['npv'] = binary_df['npv'] + monthly_npv\n",
    "        else: binary_df['npv'] = monthly_npv\n",
    "    \n",
    "    return binary_df\n",
    "\n",
    "scored_df = binary_scoring(df1, [\"month_id\", \"loan_account_no\"], \"trans_amount\", \"loan_account_no\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pie chart\n",
    "plt.figure(figsize=(15,15))\n",
    "palette_color = seaborn.color_palette('bright')\n",
    "plt.pie(a['error_description'], labels=a['index'], colors=palette_color,\n",
    "         autopct='%.0f%%')\n",
    "plt.show()\n",
    "\n",
    "#bar chart\n",
    "sns.barplot(data=axis10,y='index',x='error_description')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "#heat-map\n",
    "sns.heatmap(df.corr(),cmap =\"YlGnBu\",annot=True,linewidths = 0.1, vmax=.3, square=True)\n",
    "\n",
    "#Scatter-plot\n",
    "sns.scatterplot(data=df, x=\"freq_log\", y=\"irr_log\", hue=\"Clusters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohort analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that will parse the date Time based cohort:  1 day of month\n",
    "def get_month(x): return dt.datetime(x.year, x.month, 1) \n",
    "# Create transaction_date column based on month and store in TransactionMonth\n",
    "df1['TransactionMonth'] = df1['datetime'].apply(get_month) \n",
    "# Grouping by customer_id and select the InvoiceMonth value\n",
    "grouping = df1.groupby('account_no')['TransactionMonth'] \n",
    "# Assigning a minimum InvoiceMonth value to the dataset\n",
    "df1['CohortMonth'] = grouping.transform('min')\n",
    "\n",
    "#grouping = df1.groupby(['account_no','month_id'])['month_id'] \n",
    "## Assigning a minimum InvoiceMonth value to the dataset\n",
    "#df1['CohortMonth'] = grouping.transform('min')\n",
    "## printing top 5 rows\n",
    "\n",
    "df1['datetime']=pd.to_datetime(df1['datetime'])\n",
    "df1['CohortMonth']=pd.to_datetime(df1['CohortMonth'])\n",
    "\n",
    "def get_date_int(df1, column):\n",
    "    year = df1[column].dt.year\n",
    "    month = df1[column].dt.month\n",
    "    day = df1[column].dt.day\n",
    "    return year, month, day\n",
    "# Getting the integers for date parts from the `InvoiceDay` column\n",
    "transcation_year, transaction_month, _ = get_date_int(df1, 'datetime')\n",
    "# Getting the integers for date parts from the `CohortDay` column\n",
    "cohort_year, cohort_month, _ = get_date_int(df1, 'CohortMonth')\n",
    "\n",
    "#  Get the  difference in years\n",
    "years_diff = transcation_year - cohort_year\n",
    "# Calculate difference in months\n",
    "months_diff = transaction_month - cohort_month\n",
    "\"\"\" Extract the difference in months from all previous values\n",
    " \"+1\" in addeded at the end so that first month is marked as 1 instead of 0 for easier interpretation. \n",
    " \"\"\"\n",
    "df1['CohortIndex'] = years_diff * 12 + months_diff  + 1 \n",
    "\n",
    "# Counting daily active user from each chort\n",
    "grouping = df1.groupby(['CohortMonth', 'CohortIndex'])\n",
    "# Counting number of unique customer Id's falling in each group of CohortMonth and CohortIndex\n",
    "cohort_data = grouping['customer_id'].apply(pd.Series.nunique)\n",
    "cohort_data = cohort_data.reset_index()\n",
    " # Assigning column names to the dataframe created above\n",
    "cohort_counts = cohort_data.pivot(index='CohortMonth',\n",
    "                                 columns ='CohortIndex',\n",
    "                                 values = 'customer_id')\n",
    "# Printing top 5 rows of Dataframe\n",
    "cohort_data.head()\n",
    "\n",
    "cohort_sizes = cohort_counts.iloc[:,0]\n",
    "retention = cohort_counts\n",
    "# Coverting the retention rate into percentage and Rounding off.\n",
    "retention\n",
    "\n",
    "#average_standard_cost.index = average_standard_cost.index.strftime('%Y-%m')\n",
    "## Initialize the figure\n",
    "#plt.figure(figsize=(16, 10))\n",
    "## Adding a title\n",
    "#plt.title('Average Standard Cost: Monthly Cohorts', fontsize = 14)\n",
    "## Creating the heatmap\n",
    "sns.heatmap(retention, annot = True,vmin = 0.0, vmax =20,cmap=\"YlGnBu\", fmt='g')\n",
    "plt.ylabel('Cohort Month')\n",
    "plt.xlabel('Cohort Index')\n",
    "plt.yticks( rotation='360')\n",
    "plt.show()\n",
    "\n",
    "#To get only NEW vs Existing customer\n",
    "#create a dataframe contaning CustomerID and first purchase date\n",
    "min_mon = df.groupby('account_no').month_id.min().reset_index()\n",
    "min_mon.columns = ['account_no','minmon']\n",
    "df = pd.merge(df, min_mon, on='account_no')\n",
    "\n",
    "#create a column called User Type and assign Existing \n",
    "#if User's First Purchase Year Month before the selected Invoice Year Month\n",
    "df['UserType'] = 'New'\n",
    "df.loc[df['month_id']>df['minmon'],'UserType'] = 'Existing'\n",
    "\n",
    "## Get month wise payment method used for each customer\n",
    "pivot=pd.pivot_table(df,columns='month_id',index='account_no',values='mode',aggfunc='first').reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple streak cal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anusha Priya\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\compat\\_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#Getting sample df\n",
    "np.random.seed(12)\n",
    "seq = np.random.choice(['paid', 'not_paid'], size=100, p=[.70, .30])\n",
    "streaks = pd.Series(seq, name='collection').to_frame()\n",
    "\n",
    "#the loop\n",
    "l=[]\n",
    "curr_val = 0\n",
    "for i in streaks['collection']:\n",
    "    if i=='paid':\n",
    "        curr_val+=1\n",
    "        l.append(curr_val)\n",
    "    else:\n",
    "        curr_val=0\n",
    "        l.append(curr_val)\n",
    "streaks['streak_counter1']=l        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning experience data\n",
    "- Removing 'years' and 'month' and also chnaging to numbers according to given month or year.\n",
    "- Examples\n",
    "\n",
    "'8 Months', '2 Years', '1 Year', '2.8 Years', '2.5 yrs', '3 Years',\n",
    "       '1.2 Years', '3.4 Years', '1.8 Yrs', '1.3 yrs', '3.3 Years',\n",
    "       '3.9 Years', '4 Years', '5 Years', '6 Years', '2.6 Years',\n",
    "       '4.7 Years', '1 Yr', '8.3 Yrs', '1.6 Yrs', '1.6 Years', '8 Years',\n",
    "       '2.4 Years', '1.9 Years', '9 Years', '1.4 Yrs', '4.10 Years',\n",
    "       '1.1 Yrs', '10.6 Years', '3.10 Years', '3.5 Years', '9 Months',\n",
    "       '10 Months', '1.3 Years', '3.8 Yrs', '4.2 Years', '2.10 Years'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mon = re.compile('mon',re.IGNORECASE)\n",
    "yer = re.compile('y',re.IGNORECASE)\n",
    "l=[]\n",
    "for i in new['csr_exp']:\n",
    "    if type(i)==int or type(i)==float:\n",
    "        l.append(i)\n",
    "    elif mon.search(i) != None:\n",
    "        l.append(round(int(re.findall('\\d+',i)[0])/12,2))\n",
    "    elif yer.search(i) != None:\n",
    "        l.append(re.findall(r'\\d+(?:\\.\\d+)?',i)[0])\n",
    "    else:\n",
    "        l.append(np.nan)\n",
    "new['csr_exp']=l       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geocoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reverse geocoding - getting address from lat,long\n",
    "#!pip install geopandas\n",
    "!pip install geopy\n",
    "#import geopandas as gpd\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "geolocator = Nominatim(user_agent=\"a\")\n",
    "reverse = RateLimiter(geolocator.reverse, min_delay_seconds=0)\n",
    "location = reverse((25.207,88.581), language='en', exactly_one=True)\n",
    "location.raw['address']\n",
    "\n",
    "#To calculate distance between two coordinates and get coordinates from place name.\n",
    "from geopy import distance\n",
    "geocoder = Nominatim(user_agent='a')\n",
    "loc1 = 'delhi'\n",
    "loc2 = 'bangalore'\n",
    "coor1 = geocoder.geocode(loc1)\n",
    "coor2 = geocoder.geocode(loc2)\n",
    "#print(coor1.latitude)\n",
    "lat1,long1 = 24.1158,83.2948\n",
    "lat2,long2 = 26.3361,80.003\n",
    "p1=(lat1,long1)\n",
    "p2=(lat2,long2)\n",
    "print(distance.distance(p1,p2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
